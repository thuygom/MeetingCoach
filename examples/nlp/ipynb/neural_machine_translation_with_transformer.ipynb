{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHh-b6lBXq2c"
      },
      "source": [
        "# English-to-Spanish translation with a sequence-to-sequence Transformer\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2021/05/26<br>\n",
        "**Last modified:** 2024/11/18<br>\n",
        "**Description:** Implementing a sequence-to-sequence Transformer and training it on a machine translation task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X_GHWNaXq2e"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we'll build a sequence-to-sequence Transformer model, which\n",
        "we'll train on an English-to-Spanish machine translation task.\n",
        "\n",
        "You'll learn how to:\n",
        "\n",
        "- Vectorize text using the Keras `TextVectorization` layer.\n",
        "- Implement a `TransformerEncoder` layer, a `TransformerDecoder` layer,\n",
        "and a `PositionalEmbedding` layer.\n",
        "- Prepare data for training a sequence-to-sequence model.\n",
        "- Use the trained model to generate translations of never-seen-before\n",
        "input sentences (sequence-to-sequence inference).\n",
        "\n",
        "The code featured here is adapted from the book\n",
        "[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
        "(chapter 11: Deep learning for text).\n",
        "The present example is fairly barebones, so for detailed explanations of\n",
        "how each building block works, as well as the theory behind Transformers,\n",
        "I recommend reading the book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS8FsreMXq2e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ng9zGReqXq2f"
      },
      "outputs": [],
      "source": [
        "# We set the backend to TensorFlow. The code works with\n",
        "# both `tensorflow` and `torch`. It does not work with JAX\n",
        "# due to the behavior of `jax.numpy.tile` in a jit scope\n",
        "# (used in `TransformerDecoder.get_causal_attention_mask()`:\n",
        "# `tile` in JAX does not support a dynamic `reps` argument.\n",
        "# You can make the code work in JAX by wrapping the\n",
        "# inside of the `get_causal_attention_mask` method in\n",
        "# a decorator to prevent jit compilation:\n",
        "# `with jax.ensure_compile_time_eval():`.\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gVdbEr0Xq2g"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "We'll be working with an English-to-Spanish translation dataset\n",
        "provided by [Anki](https://www.manythings.org/anki/). Let's download it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vipb59IWXq2g",
        "outputId": "fd6eba63-878f-4139-dbaa-45d9b3b2ec36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGQCZLAjXq2g"
      },
      "source": [
        "## Parsing the data\n",
        "\n",
        "Each line contains an English sentence and its corresponding Spanish sentence.\n",
        "The English sentence is the *source sequence* and Spanish one is the *target sequence*.\n",
        "We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/root/.keras/datasets/spa-eng_extracted\"\n",
        "for root, dirs, files in os.walk(data_dir):\n",
        "    print(root, files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7VGoXdyY7fT",
        "outputId": "8cead0ec-e94d-4fa6-9d47-f7945bd4a2e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/spa-eng_extracted []\n",
            "/root/.keras/datasets/spa-eng_extracted/spa-eng ['_about.txt', 'spa.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_path = \"/root/.keras/datasets/spa-eng.zip\"\n",
        "extract_dir = \"/root/.keras/datasets/spa-eng_manual\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(os.listdir(extract_dir))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJSJMx4LZIgR",
        "outputId": "036cce47-8bdc-40a9-dfec-249f5683aa6a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['spa-eng']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B0GByIZVXq2g"
      },
      "outputs": [],
      "source": [
        "path_to_file = \"/root/.keras/datasets/spa-eng_manual/spa-eng/spa.txt\"\n",
        "\n",
        "with open(path_to_file, encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkNBPI-ZXq2h"
      },
      "source": [
        "Here's what our sentence pairs look like:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = \"/root/.keras/datasets/spa-eng_extracted/spa-eng/spa.txt\"\n",
        "\n",
        "with open(path_to_file, encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))\n",
        "\n",
        "print(\"샘플 개수:\", len(text_pairs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISTeRSnlZj3P",
        "outputId": "09ee6ee0-7ed1-4be3-d510-29fe6024f13c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플 개수: 118964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njeye0DAXq2h",
        "outputId": "3088e2a8-9995-4fe8-9cc9-1c26b5a54d93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ENG: Man is the only animal that laughs.\n",
            "SPA: [start] El único animal que ríe es el hombre. [end]\n",
            "----------------------------------------\n",
            "ENG: They robbed the man of all his belongings.\n",
            "SPA: [start] Le robaron al hombre todas sus pertenencias. [end]\n",
            "----------------------------------------\n",
            "ENG: Tom made a necklace for Mary.\n",
            "SPA: [start] Tom hizo un collar para Mary. [end]\n",
            "----------------------------------------\n",
            "ENG: Tom went shopping with his family.\n",
            "SPA: [start] Tom se fue de compras con su familia. [end]\n",
            "----------------------------------------\n",
            "ENG: Please say hello to him for me.\n",
            "SPA: [start] Por favor, salúdale por mí. [end]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def show_random_pairs(pairs, n=5):\n",
        "    samples = random.sample(pairs, n)\n",
        "    for eng, spa in samples:\n",
        "        print(f\"ENG: {eng}\")\n",
        "        print(f\"SPA: {spa}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "# 실행\n",
        "show_random_pairs(text_pairs, 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRIcpo1nXq2h"
      },
      "source": [
        "Now, let's split the sentence pairs into a training set, a validation set,\n",
        "and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SJ4m0X7Xq2h",
        "outputId": "38a0bccf-5d45-47bd-d135-e0fa5ebe43e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ],
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YEc9cheXq2h"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "We'll use two instances of the `TextVectorization` layer to vectorize the text\n",
        "data (one for English and one for Spanish),\n",
        "that is to say, to turn the original strings into integer sequences\n",
        "where each integer represents the index of a word in a vocabulary.\n",
        "\n",
        "The English layer will use the default string standardization (strip punctuation characters)\n",
        "and splitting scheme (split on whitespace), while\n",
        "the Spanish layer will use a custom standardization, where we add the character\n",
        "`\"¿\"` to the set of punctuation characters to be stripped.\n",
        "\n",
        "Note: in a production-grade machine translation model, I would not recommend\n",
        "stripping the punctuation characters in either language. Instead, I would recommend turning\n",
        "each punctuation character into its own token,\n",
        "which you could achieve by providing a custom `split` function to the `TextVectorization` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jUx8kNVNXq2h"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# 불필요한 문자 제거용 문자셋 정의\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "# 표준화 함수 정의\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "# 텍스트 벡터화 레이어\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=21  # decoder 입력은 21\n",
        ")\n",
        "\n",
        "# train_pairs 준비 (예시: text_pairs를 80%/20% split)\n",
        "split = int(len(text_pairs) * 0.8)\n",
        "train_pairs = text_pairs[:split]\n",
        "val_pairs = text_pairs[split:]\n",
        "\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "\n",
        "# 어휘 사전 적합\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HmejISzXq2h"
      },
      "source": [
        "Next, we'll format our datasets.\n",
        "\n",
        "At each training step, the model will seek to predict target words N+1 (and beyond)\n",
        "using the source sentence and the target words 0 to N.\n",
        "\n",
        "As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n",
        "\n",
        "- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n",
        "`encoder_inputs` is the vectorized source sentence and `decoder_inputs` is the target sentence \"so far\",\n",
        "that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n",
        "- `target` is the target sentence offset by one step:\n",
        "it provides the next words in the target sentence -- what the model will try to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9vu5aHxXq2i",
        "outputId": "56935868-a597-4bb5-c273-188526ad54ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_inputs: (64, 20)\n",
            "decoder_inputs: (64, 20)\n",
            "targets: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)    # (batch, 20)\n",
        "    spa = spa_vectorization(spa)    # (batch, 21)\n",
        "\n",
        "    # 디코더 입력: 맨 마지막 토큰([end]) 제거 → (batch, 20)\n",
        "    decoder_in = spa[:, :-1]\n",
        "\n",
        "    # 타깃: 맨 첫 토큰([start]) 제거 → (batch, 20)\n",
        "    target = spa[:, 1:]\n",
        "\n",
        "    return {\"encoder_inputs\": eng, \"decoder_inputs\": decoder_in}, target\n",
        "\n",
        "\n",
        "def make_dataset(pairs, batch_size=batch_size, shuffle=True):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(eng_texts), list(spa_texts)))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=AUTOTUNE)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(2048, reshuffle_each_iteration=True)\n",
        "    return dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 학습/검증 데이터셋 준비\n",
        "train_ds = make_dataset(train_pairs, batch_size=batch_size, shuffle=True)\n",
        "val_ds = make_dataset(val_pairs, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 확인\n",
        "for batch in train_ds.take(1):\n",
        "    inputs, targets = batch\n",
        "    print(\"encoder_inputs:\", inputs[\"encoder_inputs\"].shape)\n",
        "    print(\"decoder_inputs:\", inputs[\"decoder_inputs\"].shape)\n",
        "    print(\"targets:\", targets.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Bx-5p2Xq2i"
      },
      "source": [
        "Let's take a quick look at the sequence shapes\n",
        "(we have batches of 64 pairs, and all sequences are 20 steps long):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd2p22uOXq2i",
        "outputId": "14357490-60f9-4b1f-d39a-d18574ef6f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ6LtOjiXq2i"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together. To make the model aware of word order,\n",
        "we also use a `PositionalEmbedding` layer.\n",
        "\n",
        "The source sequence will be pass to the `TransformerEncoder`,\n",
        "which will produce a new representation of it.\n",
        "This new representation will then be passed\n",
        "to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n",
        "\n",
        "A key detail that makes this possible is causal masking\n",
        "(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n",
        "The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n",
        "sure that it only uses information from target tokens 0 to N when predicting token N+1\n",
        "(otherwise, it could use information from the future, which would\n",
        "result in a model that cannot be used at inference time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3gH_2zRZXq2i"
      },
      "outputs": [],
      "source": [
        "# ✅ Keras3/TF용: 바로 실행 가능 리팩터\n",
        "import keras\n",
        "from keras import layers\n",
        "import keras.ops as ops\n",
        "\n",
        "# ---------------------------\n",
        "# Positional + Token Embedding\n",
        "# ---------------------------\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, dropout=0.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(vocab_size, embed_dim, mask_zero=True)\n",
        "        self.position_embeddings = layers.Embedding(sequence_length, embed_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dropout = layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        # inputs: (B, T)\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)  # (T,)\n",
        "        x = self.token_embeddings(inputs)                     # (B, T, D)\n",
        "        pos = self.position_embeddings(positions)[None, ...]  # (1, T, D)\n",
        "        x = x + pos\n",
        "        return self.dropout(x, training=training)\n",
        "\n",
        "    # mask_zero=True로 자동 마스크 생성\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update(dict(sequence_length=self.sequence_length,\n",
        "                        vocab_size=self.vocab_size,\n",
        "                        embed_dim=self.embed_dim))\n",
        "        return cfg\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Transformer Encoder\n",
        "# ---------------------------\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, ff_dim, num_heads, dropout=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout)\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dropout(dropout),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.drop = layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, x, mask=None, training=False):\n",
        "        # mask: (B, T) boolean -> (B, 1, T)로 확장해서 MHA에 전달\n",
        "        attn_mask = None\n",
        "        if mask is not None:\n",
        "            attn_mask = ops.expand_dims(ops.cast(mask, \"bool\"), axis=1)  # (B,1,T)\n",
        "\n",
        "        attn_out = self.attn(query=x, value=x, key=x, attention_mask=attn_mask, training=training)\n",
        "        x = self.norm1(x + self.drop(attn_out, training=training))\n",
        "        ffn_out = self.ffn(x, training=training)\n",
        "        x = self.norm2(x + self.drop(ffn_out, training=training))\n",
        "        return x\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update(dict(embed_dim=self.embed_dim, ff_dim=self.ff_dim, num_heads=self.num_heads))\n",
        "        return cfg\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Transformer Decoder\n",
        "# ---------------------------\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, ff_dim, num_heads, dropout=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.self_attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout)\n",
        "        self.cross_attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim, dropout=dropout)\n",
        "        self.ffn = keras.Sequential([\n",
        "            layers.Dense(ff_dim, activation=\"relu\"),\n",
        "            layers.Dropout(dropout),\n",
        "            layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.norm3 = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.drop = layers.Dropout(dropout)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    @staticmethod\n",
        "    def _causal_mask(x):\n",
        "        # x: (B, T, D) or (B, T)\n",
        "        T = ops.shape(x)[-2] if len(x.shape) == 3 else ops.shape(x)[-1]\n",
        "        i = ops.arange(T)[:, None]\n",
        "        j = ops.arange(T)[None, :]\n",
        "        mask = i >= j  # (T,T) lower-triangular\n",
        "        return mask  # boolean\n",
        "\n",
        "    def call(self, inputs, mask=None, training=False):\n",
        "        # inputs: (dec_inputs, enc_outputs)\n",
        "        dec, enc = inputs\n",
        "        # mask: (dec_mask, enc_mask) from Keras masking (boolean, shape (B,T))\n",
        "        dec_mask = enc_mask = None\n",
        "        if mask is not None:\n",
        "            dec_mask, enc_mask = mask\n",
        "\n",
        "        # 1) Causal + padding mask for self-attn\n",
        "        causal = self._causal_mask(dec)                      # (T,T)\n",
        "        causal = ops.expand_dims(causal, 0)                  # (1,T,T)\n",
        "        if dec_mask is not None:\n",
        "            # dec_mask: (B,T) -> (B,1,T) to allow padding on keys\n",
        "            pad_k = ops.expand_dims(ops.cast(dec_mask, \"bool\"), 1)  # (B,1,T)\n",
        "            # broadcast causal to (B,T,T)\n",
        "            B = ops.shape(dec)[0]\n",
        "            causal = ops.tile(causal, (B, 1, 1))             # (B,T,T)\n",
        "            # combine: valid only if both causal & key not padded\n",
        "            self_attn_mask = ops.logical_and(causal, pad_k)  # (B,1,T) broadcast on query dim\n",
        "        else:\n",
        "            self_attn_mask = causal  # (1,T,T) -> broadcast\n",
        "\n",
        "        sa = self.self_attn(dec, dec, dec, attention_mask=self_attn_mask, training=training)\n",
        "        x = self.norm1(dec + self.drop(sa, training=training))\n",
        "\n",
        "        # 2) Cross-attn: query=x (B,Td,D), key/value=enc (B,Te,D)\n",
        "        cross_mask = None\n",
        "        if enc_mask is not None:\n",
        "            cross_mask = ops.expand_dims(ops.cast(enc_mask, \"bool\"), 1)  # (B,1,Te)\n",
        "\n",
        "        ca = self.cross_attn(x, enc, enc, attention_mask=cross_mask, training=training)\n",
        "        x2 = self.norm2(x + self.drop(ca, training=training))\n",
        "\n",
        "        ffn_out = self.ffn(x2, training=training)\n",
        "        out = self.norm3(x2 + self.drop(ffn_out, training=training))\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        cfg = super().get_config()\n",
        "        cfg.update(dict(embed_dim=self.embed_dim, ff_dim=self.ff_dim, num_heads=self.num_heads))\n",
        "        return cfg\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 모델 조립 helper\n",
        "# ---------------------------\n",
        "def build_nmt_model(\n",
        "    src_vocab_size, tgt_vocab_size,\n",
        "    src_seq_len=20, tgt_seq_len=20,   # decoder_inputs는 20으로 맞춤\n",
        "    embed_dim=256, ff_dim=512, num_heads=4, dropout=0.1\n",
        "):\n",
        "    # Encoder\n",
        "    enc_inputs = layers.Input(shape=(src_seq_len,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "    enc_embed = PositionalEmbedding(src_seq_len, src_vocab_size, embed_dim, dropout=dropout)(enc_inputs)\n",
        "    enc_out = TransformerEncoder(embed_dim, ff_dim, num_heads, dropout=dropout)(enc_embed)\n",
        "\n",
        "    # Decoder (길이 20)\n",
        "    dec_inputs = layers.Input(shape=(tgt_seq_len,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "    dec_embed = PositionalEmbedding(tgt_seq_len, tgt_vocab_size, embed_dim, dropout=dropout)(dec_inputs)\n",
        "    dec_out = TransformerDecoder(embed_dim, ff_dim, num_heads, dropout=dropout)([dec_embed, enc_out])\n",
        "\n",
        "    # LM head\n",
        "    logits = layers.Dense(tgt_vocab_size, name=\"logits\")(dec_out)\n",
        "\n",
        "    model = keras.Model([enc_inputs, dec_inputs], logits, name=\"TransformerNMT\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True, ignore_class=0),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        "    )\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFmkc7DRXq2i"
      },
      "source": [
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "_gVmVvIOXq2i",
        "outputId": "5363af75-5b53-4ec3-8318-781f0c547ab6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,845,376\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m5,259,520\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m15000\u001b[0m) │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,376</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,472\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,472</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,472\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,472</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "embed_dim = 256\n",
        "ff_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(sequence_length,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, ff_dim, num_heads)(x)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(sequence_length+1,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length+1, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, ff_dim, num_heads)([x, encoder_outputs])\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size)(x)  # softmax 안 씀 (from_logits=True)\n",
        "\n",
        "# 최종 모델\n",
        "transformer = keras.Model(\n",
        "    inputs={\"encoder_inputs\": encoder_inputs, \"decoder_inputs\": decoder_inputs},\n",
        "    outputs=decoder_outputs,\n",
        "    name=\"transformer\",\n",
        ")\n",
        "\n",
        "# 컴파일 (로짓 출력 → from_logits=True)\n",
        "transformer.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        ")\n",
        "\n",
        "transformer.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqgBr67UXq2i"
      },
      "source": [
        "## Training our model\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n",
        "\n",
        "Here we only train for 1 epoch, but to get the model to actually converge\n",
        "you should train for at least 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "WmVv1IhfXq2i",
        "outputId": "86c2ee54-ea3d-4f90-b5fb-5400a182af01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,845,376\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m5,259,520\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m15000\u001b[0m) │  \u001b[38;5;34m3,855,000\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,376</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,855,000</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,472\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,472</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,472\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,472</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"transformer\" is incompatible with the layer: expected shape=(None, 21), found shape=(None, 20)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1384300342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = transformer.fit(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"transformer\" is incompatible with the layer: expected shape=(None, 21), found shape=(None, 20)"
          ]
        }
      ],
      "source": [
        "epochs = 1  # 실제 수렴을 위해서는 최소 30 이상 권장\n",
        "\n",
        "transformer.summary()\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True, ignore_class=0),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")],\n",
        ")\n",
        "\n",
        "history = transformer.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_ds,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# -----------------------------\n",
        "# 0. GPU 확인 및 세팅\n",
        "# -----------------------------\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))\n",
        "print(\"GPU Device:\", tf.test.gpu_device_name())\n",
        "\n",
        "# GPU 메모리 증가 설정 (OOM 방지)\n",
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# -----------------------------\n",
        "# 1. 데이터 준비 (vectorization)\n",
        "# -----------------------------\n",
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)      # (batch, 20)\n",
        "    spa = spa_vectorization(spa)      # (batch, 21)\n",
        "\n",
        "    decoder_in = spa[:, :-1]          # (batch, 20)\n",
        "    target = spa[:, 1:]               # (batch, 20)\n",
        "\n",
        "    return {\"encoder_inputs\": eng, \"decoder_inputs\": decoder_in}, target\n",
        "\n",
        "train_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices((train_eng_texts, train_spa_texts))\n",
        "    .batch(64)\n",
        "    .map(format_dataset)\n",
        "    .shuffle(2048)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "val_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(([p[0] for p in val_pairs], [p[1] for p in val_pairs]))\n",
        "    .batch(64)\n",
        "    .map(format_dataset)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 2. 모델 정의 (PositionalEmbedding / Encoder / Decoder는 이미 정의돼 있다고 가정)\n",
        "# -----------------------------\n",
        "def build_nmt_model(\n",
        "    src_vocab_size, tgt_vocab_size,\n",
        "    src_seq_len=20, tgt_seq_len=20,\n",
        "    embed_dim=256, ff_dim=512, num_heads=4, dropout=0.1\n",
        "):\n",
        "    # Encoder\n",
        "    enc_inputs = layers.Input(shape=(src_seq_len,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "    enc_embed = PositionalEmbedding(src_seq_len, src_vocab_size, embed_dim, dropout=dropout)(enc_inputs)\n",
        "    enc_out = TransformerEncoder(embed_dim, ff_dim, num_heads, dropout=dropout)(enc_embed)\n",
        "\n",
        "    # Decoder\n",
        "    dec_inputs = layers.Input(shape=(tgt_seq_len,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "    dec_embed = PositionalEmbedding(tgt_seq_len, tgt_vocab_size, embed_dim, dropout=dropout)(dec_inputs)\n",
        "    dec_out = TransformerDecoder(embed_dim, ff_dim, num_heads, dropout=dropout)([dec_embed, enc_out])\n",
        "\n",
        "    # LM head\n",
        "    logits = layers.Dense(tgt_vocab_size, name=\"logits\")(dec_out)\n",
        "\n",
        "    model = keras.Model([enc_inputs, dec_inputs], logits, name=\"TransformerNMT\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True, ignore_class=0),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# -----------------------------\n",
        "# 3. 모델 생성 및 학습 (GPU 자동 사용)\n",
        "# -----------------------------\n",
        "transformer = build_nmt_model(\n",
        "    src_vocab_size=vocab_size,\n",
        "    tgt_vocab_size=20000,\n",
        "    src_seq_len=20,\n",
        "    tgt_seq_len=20\n",
        ")\n",
        "\n",
        "transformer.summary()\n",
        "\n",
        "with tf.device(\"/GPU:0\"):   # 명시적으로 GPU에 올리고 싶을 때\n",
        "    history = transformer.fit(\n",
        "        train_ds,\n",
        "        epochs=30,              # 테스트라서 1, 실제는 30 이상 권장\n",
        "        validation_data=val_ds\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-wFjfkdTdvoV",
        "outputId": "8ce7ba17-5250-4209-b48c-b0d44d4125e9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Num GPUs Available: 1\n",
            "GPU Device: /device:GPU:0\n",
            "Physical devices cannot be modified after being initialized\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"TransformerNMT\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"TransformerNMT\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m5,125,120\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,315,840\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m2,368,256\u001b[0m │ positional_embed… │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ logits (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20000\u001b[0m) │  \u001b[38;5;34m5,140,000\u001b[0m │ transformer_deco… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125,120</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,840</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368,256</span> │ positional_embed… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ logits (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140,000</span> │ transformer_deco… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,794,336\u001b[0m (67.88 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,794,336</span> (67.88 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,794,336\u001b[0m (67.88 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,794,336</span> (67.88 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 37ms/step - acc: 0.0978 - loss: 5.3468 - val_acc: 0.1946 - val_loss: 2.6567\n",
            "Epoch 2/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2051 - loss: 2.4625 - val_acc: 0.2257 - val_loss: 1.9543\n",
            "Epoch 3/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2353 - loss: 1.7297 - val_acc: 0.2363 - val_loss: 1.7129\n",
            "Epoch 4/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2510 - loss: 1.3598 - val_acc: 0.2421 - val_loss: 1.5972\n",
            "Epoch 5/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2633 - loss: 1.1161 - val_acc: 0.2438 - val_loss: 1.5782\n",
            "Epoch 6/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2721 - loss: 0.9568 - val_acc: 0.2457 - val_loss: 1.5542\n",
            "Epoch 7/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2784 - loss: 0.8405 - val_acc: 0.2472 - val_loss: 1.5570\n",
            "Epoch 8/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2841 - loss: 0.7634 - val_acc: 0.2482 - val_loss: 1.5648\n",
            "Epoch 9/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2880 - loss: 0.7008 - val_acc: 0.2485 - val_loss: 1.5778\n",
            "Epoch 10/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2925 - loss: 0.6479 - val_acc: 0.2486 - val_loss: 1.5905\n",
            "Epoch 11/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2955 - loss: 0.6083 - val_acc: 0.2489 - val_loss: 1.6042\n",
            "Epoch 12/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.2975 - loss: 0.5681 - val_acc: 0.2493 - val_loss: 1.6296\n",
            "Epoch 13/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3011 - loss: 0.5429 - val_acc: 0.2493 - val_loss: 1.6507\n",
            "Epoch 14/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3026 - loss: 0.5187 - val_acc: 0.2490 - val_loss: 1.6635\n",
            "Epoch 15/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3047 - loss: 0.4936 - val_acc: 0.2490 - val_loss: 1.6793\n",
            "Epoch 16/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3062 - loss: 0.4784 - val_acc: 0.2494 - val_loss: 1.6936\n",
            "Epoch 17/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3074 - loss: 0.4590 - val_acc: 0.2495 - val_loss: 1.7123\n",
            "Epoch 18/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - acc: 0.3094 - loss: 0.4417 - val_acc: 0.2495 - val_loss: 1.7290\n",
            "Epoch 19/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - acc: 0.3091 - loss: 0.4290 - val_acc: 0.2494 - val_loss: 1.7565\n",
            "Epoch 20/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3118 - loss: 0.4166 - val_acc: 0.2493 - val_loss: 1.7750\n",
            "Epoch 21/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3118 - loss: 0.4057 - val_acc: 0.2493 - val_loss: 1.7974\n",
            "Epoch 22/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3126 - loss: 0.3935 - val_acc: 0.2492 - val_loss: 1.8100\n",
            "Epoch 23/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3141 - loss: 0.3840 - val_acc: 0.2493 - val_loss: 1.8231\n",
            "Epoch 24/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3140 - loss: 0.3736 - val_acc: 0.2497 - val_loss: 1.8371\n",
            "Epoch 25/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3158 - loss: 0.3691 - val_acc: 0.2499 - val_loss: 1.8428\n",
            "Epoch 26/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3159 - loss: 0.3595 - val_acc: 0.2492 - val_loss: 1.8514\n",
            "Epoch 27/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3171 - loss: 0.3522 - val_acc: 0.2495 - val_loss: 1.8818\n",
            "Epoch 28/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3172 - loss: 0.3461 - val_acc: 0.2490 - val_loss: 1.8788\n",
            "Epoch 29/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3181 - loss: 0.3420 - val_acc: 0.2495 - val_loss: 1.8898\n",
            "Epoch 30/30\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - acc: 0.3189 - loss: 0.3326 - val_acc: 0.2496 - val_loss: 1.9012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJXGlwqwdtLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyvv0RyEXq2i"
      },
      "source": [
        "## Decoding test sentences\n",
        "\n",
        "Finally, let's demonstrate how to translate brand new English sentences.\n",
        "We simply feed into the model the vectorized English sentence\n",
        "as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n",
        "we hit the token `\"[end]\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8powKNk9Xq2i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from keras import ops\n",
        "\n",
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    # 영어 문장 → 벡터화\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "\n",
        "    # 시작 토큰 세팅\n",
        "    decoded_sentence = \"[start]\"\n",
        "\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        # 현재까지의 번역 결과를 decoder 입력으로 변환\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "\n",
        "        # 모델 예측 (logits 반환)\n",
        "        predictions = transformer(\n",
        "            {\n",
        "                \"encoder_inputs\": tokenized_input_sentence,\n",
        "                \"decoder_inputs\": tokenized_target_sentence,\n",
        "            },\n",
        "            training=False,\n",
        "        )\n",
        "\n",
        "        # 현재 step에서 가장 높은 확률 토큰 뽑기\n",
        "        sampled_token_index = int(\n",
        "            np.argmax(predictions[0, i, :].numpy())\n",
        "        )\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "\n",
        "        # 토큰 추가\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        # 종료 토큰 나오면 중단\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(f\"EN: {input_sentence}\")\n",
        "    print(f\"ES: {translated}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "tGKInhANhplr",
        "outputId": "6c631fcc-cb3b-487d-88d8-3736f35ce6fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EN: I like to eat Korean food.\n",
            "ES: [start] me gusta comer comida coreana end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: He enjoyed playing baseball.\n",
            "ES: [start] Él disfrutaba jugar béisbol end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: I feel like going on a trip.\n",
            "ES: [start] tengo ganas de ir en un viaje end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Tom is right, of course.\n",
            "ES: [start] tom tiene razón por supuesto end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Tom laughs at his own jokes.\n",
            "ES: [start] tom se ríe de sus propias bromas end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: I'll be back by 2:30.\n",
            "ES: [start] estaré de vuelta para las dos y media end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Tom knows Mary won't tell John.\n",
            "ES: [start] tom conoce a mary no a decirle a john end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: They don't despise you.\n",
            "ES: [start] no te desprecian end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: I know what you're scheming to do.\n",
            "ES: [start] sé lo que eres que te sorprenderías end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: We'll fail.\n",
            "ES: [start] bueno no logro end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Not all Americans shared Wilson's opinion.\n",
            "ES: [start] no todos los americanos son gente de carácter end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: He disappeared without a trace.\n",
            "ES: [start] desapareció sin rastro end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Don't touch these.\n",
            "ES: [start] no toques éstos end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Mary has beautiful eyes.\n",
            "ES: [start] mary tiene unos ojos hermosos end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: My nephew was accustomed to staying up late.\n",
            "ES: [start] mi sobrino fue acostumbrado a quedarme hasta tarde end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Atoms cannot be seen with your own eye.\n",
            "ES: [start] no pueden ver con tus propios ojos end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Having a slight cold, I went to bed early.\n",
            "ES: [start] como estaba un poco de frío me fui a la cama temprano end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: You guys are wrong.\n",
            "ES: [start] ustedes están equivocados end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: I'm sorry, but it's impossible.\n",
            "ES: [start] lo siento pero es imposible end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: It is not raining.\n",
            "ES: [start] no está lloviendo end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Wait one second.\n",
            "ES: [start] espera un segundo end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: I asked how Tom was.\n",
            "ES: [start] pregunté como tom era end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Nobody knew what to say.\n",
            "ES: [start] nadie sabía qué decir end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: I have been to the airport to see him off.\n",
            "ES: [start] he estado en el aeropuerto para despedirme de él end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: She looked at me with tears running down her cheeks.\n",
            "ES: [start] ella me miró con lágrimas [UNK] por sus mejillas end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: I speak a little French.\n",
            "ES: [start] hablo un poco de francés end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Tom had his ear pressed to the door, trying to hear what was going on in the next room.\n",
            "ES: [start] tom tenía la oreja pegada en la puerta tratando de oír lo que estaba pasando en la habitación de al\n",
            "--------------------------------------------------\n",
            "EN: I can't allow that to happen.\n",
            "ES: [start] no puedo permitir que eso pase end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Who cheated?\n",
            "ES: [start] ¿quién hizo trampa end end end end end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n",
            "EN: Look at the large building over there.\n",
            "ES: [start] mira el edificio grande y otra allí end end end end end end end end end end end end end\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLCwATaeXq2i"
      },
      "source": [
        "After 30 epochs, we get results such as:\n",
        "\n",
        "> She handed him the money.\n",
        "> [start] ella le pasó el dinero [end]\n",
        "\n",
        "> Tom has never heard Mary sing.\n",
        "> [start] tom nunca ha oído cantar a mary [end]\n",
        "\n",
        "> Perhaps she will come tomorrow.\n",
        "> [start] tal vez ella vendrá mañana [end]\n",
        "\n",
        "> I love to write.\n",
        "> [start] me encanta escribir [end]\n",
        "\n",
        "> His French is improving little by little.\n",
        "> [start] su francés va a [UNK] sólo un poco [end]\n",
        "\n",
        "> My hotel told me to call you.\n",
        "> [start] mi hotel me dijo que te [UNK] [end]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "neural_machine_translation_with_transformer",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}